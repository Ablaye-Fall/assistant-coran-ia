# assistant-coran-ia/app.py
import streamlit as st
import requests
import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer, util
from deep_translator import GoogleTranslator
from sentence_transformers import SentenceTransformer

# === Chargement modÃ¨le sÃ©mantique ===
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")

# Charger le modÃ¨le lÃ©ger
model = SentenceTransformer("all-MiniLM-L6-v2")

# === Chargement du fichier tafsir ===
with open("tafsir_fr_complet.json", "r", encoding="utf-8") as f:
    tafsir_data = json.load(f)
# PrÃ©parer les clÃ©s et textes
tafsir_keys = list(tafsir_data.keys())
tafsir_texts = list(tafsir_data.values())

# Encoder tous les tafsir (Ã  faire une seule fois)
tafsir_embeddings = model.encode(tafsir_texts, convert_to_tensor=True)

def trouver_tafsir_semantique(texte_verset):
    """
    Trouve le tafsir le plus proche sÃ©mantiquement du texte du verset donnÃ©.
    """
    # Encoder la requÃªte
    query_embedding = model.encode(texte_verset, convert_to_tensor=True)
    
    # Calculer la similaritÃ©
    scores = util.pytorch_cos_sim(query_embedding, tafsir_embeddings)[0]
    
    # Trouver le meilleur score
    best_idx = scores.argmax()
    meilleur_tafsir = tafsir_texts[best_idx]
    cle_associee = tafsir_keys[best_idx]
    
    return cle_associee, meilleur_tafsir
    
def traduire_texte(texte, langue_cible):
    """
    Traduit le texte donnÃ© vers la langue cible (ex: 'en', 'ar', 'fr', 'wolof')
    """
    try:
        traduction = GoogleTranslator(source='auto', target=langue_cible).translate(texte)
        return traduction
    except Exception as e:
        return f"Erreur de traduction : {e}"    

# === Construction index sÃ©mantique FAISS ===
tafsir_texts = []
tafsir_keys = []
for surah, verses in tafsir_data.items():
    for ayah, text in verses.items():
        tafsir_texts.append(text)
        tafsir_keys.append((surah, ayah))

embeddings = model.encode(tafsir_texts)
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(np.array(embeddings))

# === Fonctions API AlQuran.cloud ===
def get_surah_list():
    url = "http://api.alquran.cloud/v1/surah"
    response = requests.get(url)
    return response.json()["data"]

def get_verses(surah_number, translation_code="en.asad"):
    url = f"http://api.alquran.cloud/v1/surah/{surah_number}/editions/quran-simple,{translation_code}"
    response = requests.get(url)
    return response.json()["data"]

# === Interface Streamlit ===
st.set_page_config(page_title="Assistant Coran IA", layout="centered")
st.title("ğŸ“– Assistant Coran avec NLP")

# SÃ©lection de la sourate
surahs = get_surah_list()
surah_names = [f"{s['number']}. {s['englishName']} ({s['name']})" for s in surahs]
surah_choice = st.selectbox("ğŸ“š Choisissez une sourate :", surah_names)
surah_number = int(surah_choice.split('.')[0])

# SÃ©lection de la langue
translation_options = {
    "ğŸ‡«ğŸ‡· FranÃ§ais (Hamidullah)": "fr.hamidullah",
    "ğŸ‡¬ğŸ‡§ English (Muhammad Asad)": "en.asad",
    "ğŸ‡®ğŸ‡© IndonÃ©sien": "id.indonesian",
    "ğŸ‡¹ğŸ‡· Turc": "tr.translator",
    "ğŸ‡ºğŸ‡¿ Ouzbek": "uz.sodik"
}
translation_label = st.selectbox("ğŸŒ Choisir une langue de traduction :", list(translation_options.keys()))
translation_code = translation_options[translation_label]

# RÃ©cupÃ©ration des versets
verses_data = get_verses(surah_number, translation_code)
versets = verses_data[0]['ayahs']
traductions = verses_data[1]['ayahs']

# SÃ©lection du verset
verse_index = st.number_input("ğŸ“Œ Choisir le numÃ©ro du verset :", min_value=1, max_value=len(versets), value=1)
selected_verse = versets[verse_index - 1]
translated_verse = traductions[verse_index - 1]

# Affichage
st.markdown("### ğŸ•‹ Verset en arabe")
st.markdown(f"**{selected_verse['text']}**")

st.markdown(f"### ğŸŒ Traduction ({translation_label})")
st.markdown(f"*{translated_verse['text']}*")

# Tafsir classique (local)
st.markdown("### ğŸ“– Tafsir classique (extrait)")
tafsir_key = f"{int(surah_number)}:{int(verse_index)}"
tafsir_entry = tafsir_data.get(tafsir_key)
if tafsir_entry:
    st.markdown(f"*Source : {tafsir_entry.get('source', 'non spÃ©cifiÃ©e')}*")
    st.write(tafsir_entry.get("tafsir", "Contenu non disponible."))
else:
    st.warning("âš ï¸ Aucun tafsir trouvÃ© pour ce verset.")

# Recherche sÃ©mantique
st.markdown("---")
st.markdown("## ğŸ” Recherche sÃ©mantique dans le Tafsir")
query = st.text_input("Entrez un mot-clÃ© ou une question :")
if query:
    query_vector = model.encode([query])
    D, I = index.search(np.array(query_vector), k=3)
    for idx in I[0]:
        surah, ayah = tafsir_keys[idx]
        st.markdown(f"**Sourate {surah}, Verset {ayah}**")
        st.write(tafsir_data[surah][ayah])

# Question-RÃ©ponse (placeholder Ã  complÃ©ter avec un modÃ¨le local ou GPT)
st.markdown("---")
st.markdown("## â“ Posez une question sur un verset ou tafsir")
question = st.text_input("Votre question :")
if question:
    st.info("ğŸ”§ Fonction de rÃ©ponse Ã  la question Ã  intÃ©grer avec modÃ¨le local ou GPT.")


